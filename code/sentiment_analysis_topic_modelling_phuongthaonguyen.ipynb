{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Applied Natural Language Processing - AT2 - HDInnovators\n",
        "__Content:__\n",
        "\n",
        "1. Import packages and create functions\n",
        "2. Load the dataset\n",
        "3. Data preparation\n",
        "4. Data exploration\n",
        "5. Sentiment analysis\n",
        "\n",
        "  5.1. RandomForest \n",
        "  \n",
        "  5.2. LSTM\n",
        "\n",
        "6. Topic Modelling"
      ],
      "metadata": {
        "id": "tlI9QnDVnagQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import packages and create function"
      ],
      "metadata": {
        "id": "GPzq-Phyol5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "metadata": {
        "id": "3y_IWgbLbCCc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if len(device_name) > 0:\n",
        "    print(\"Found GPU at: {}\".format(device_name))\n",
        "else:\n",
        "    device_name = \"/device:CPU:0\"\n",
        "    print(\"No GPU, using {}.\".format(device_name))\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97eSUJ6XZ_cU",
        "outputId": "c827e839-160d-4cdc-f5cb-1df89fa7726f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data processing\n",
        "import pandas as pd\n",
        "import re\n",
        "import spacy\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "# nltk\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# data splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# hyperparameter tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import keras_tuner as kt\n",
        "\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# vectorization\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# tensorflow deep learning \n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, Flatten, SpatialDropout1D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# RandomForest classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# evaluation \n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ignore warnings \n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "id": "2GpgXL1FH_8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78cd53ee-8465-486c-f6fa-84a58e0bd8c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a function to transform valence sentiment labels\n",
        "def create_sentiment_from_valence(valence):\n",
        "   if valence < 0.45:\n",
        "     return 0\n",
        "   elif valence > 0.55:\n",
        "     return 2\n",
        "   else:\n",
        "     return 1"
      ],
      "metadata": {
        "id": "dm_00T1BQnsz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load and explore the dataset"
      ],
      "metadata": {
        "id": "FufJTQrwo89L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Load dataset__"
      ],
      "metadata": {
        "id": "4zep39NepWLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading dataset\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/content/lyrics_all_combined.csv')"
      ],
      "metadata": {
        "id": "cG46E1rbIE2n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data preparation"
      ],
      "metadata": {
        "id": "vPLVlvzGqG9t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Lowercase__"
      ],
      "metadata": {
        "id": "r7xogmO5pY5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all data of lyrics to string type.\n",
        "df['lyrics'] = df['lyrics'].apply(str)\n",
        "\n",
        "# Convert all string of lyrics to lowercase.\n",
        "df['lyrics'] = df['lyrics'].str.lower()"
      ],
      "metadata": {
        "id": "QiDCvtSEJwW3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " __Tokenize__"
      ],
      "metadata": {
        "id": "-YaNEIDSpijq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize text from lyrics. \n",
        "df['tokenized'] = df['lyrics'].apply(word_tokenize)"
      ],
      "metadata": {
        "id": "-Hbewgleps_K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Remove punctuations__"
      ],
      "metadata": {
        "id": "GzzI39TcptxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All punctuations\n",
        "punc_marks = list(string.punctuation)\n",
        "# Remove all punctuations.\n",
        "df['tokenized'] = df['tokenized'].apply(lambda x: [word for word in x if word not in punc_marks])"
      ],
      "metadata": {
        "id": "9-Fnx3CTp1i_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Remove stopwords__"
      ],
      "metadata": {
        "id": "mebHZRsrqBkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All stopwords of nltk\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "# Customized list of stop words.\n",
        "stopwords.extend([\"'m\", \"'s\", \"'d\", \"hi\", \"im\", \"wa\", \"n't\", \"'get\", \"'ll\", \"'re\", \"'ve\", \"get\", \"still\", \"mmm\", \"ooh\", \"oooh\", \"yah\", \"yeh\",\"mmm\", \"hmm\"])\n",
        "\n",
        "# Remove the stop words from the dataset and save the result to new column. \n",
        "df['cleaned_stopwords'] = df['tokenized'].apply(lambda x: [word for word in x if word not in stopwords])"
      ],
      "metadata": {
        "id": "tbxDo4tVIrYU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Lemmatize__"
      ],
      "metadata": {
        "id": "-vGIOfVEqbVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to attain part of speech of words.\n",
        "def determine_wordnet_speech(word_tag):\n",
        "    if word_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif word_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif word_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif word_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "    \n",
        "# Add part of speech tags and save the result to new column.\n",
        "df['pos_tags'] = df['cleaned_stopwords'].apply(nltk.tag.pos_tag)\n",
        "\n",
        "# Function to get part of speech in WordNet format.\n",
        "df['pos_tags'] = df['pos_tags'].apply(lambda x: [(word, determine_wordnet_speech(pos_tag)) for (word, pos_tag) in x])\n",
        "\n",
        "# Lemmatize words and save the result to new column.\n",
        "word_lemmatizer = WordNetLemmatizer()\n",
        "df['lyrics_lemmatized'] = df['pos_tags'].apply(lambda x: [word_lemmatizer.lemmatize(word, tag) for word, tag in x])\n",
        "\n",
        "# Convert list to string datatype. \n",
        "df['lyrics_cleaned'] = [' '.join(map(str,l)) for l in df['lyrics_lemmatized']]\n",
        "\n",
        "# Check few rows.\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "iX5UYCkBKnp5",
        "outputId": "5221c2dd-840a-467c-a130-1a728c1967bf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0           artist_name            track_name  release_date  \\\n",
              "0       13923               santana                 wham!          1978   \n",
              "1       14958          marvin sease  show me what you got          1991   \n",
              "2       15045  the robert cray band            1040 blues          1993   \n",
              "\n",
              "   genre                                             lyrics  len   valence  \\\n",
              "0  blues  cold chamber smoke kush gettin higher plane sw...  198  0.857791   \n",
              "1  blues  public service announcement weezy baby best ra...  198  0.794930   \n",
              "2  blues  gotta rapper today forget fuck smokin brain ce...  198  0.613561   \n",
              "\n",
              "                                           tokenized  \\\n",
              "0  [cold, chamber, smoke, kush, gettin, higher, p...   \n",
              "1  [public, service, announcement, weezy, baby, b...   \n",
              "2  [got, ta, rapper, today, forget, fuck, smokin,...   \n",
              "\n",
              "                                   cleaned_stopwords  \\\n",
              "0  [cold, chamber, smoke, kush, gettin, higher, p...   \n",
              "1  [public, service, announcement, weezy, baby, b...   \n",
              "2  [got, ta, rapper, today, forget, fuck, smokin,...   \n",
              "\n",
              "                                            pos_tags  \\\n",
              "0  [(cold, a), (chamber, n), (smoke, v), (kush, n...   \n",
              "1  [(public, a), (service, n), (announcement, n),...   \n",
              "2  [(got, v), (ta, a), (rapper, n), (today, n), (...   \n",
              "\n",
              "                                   lyrics_lemmatized  \\\n",
              "0  [cold, chamber, smoke, kush, gettin, high, pla...   \n",
              "1  [public, service, announcement, weezy, baby, b...   \n",
              "2  [get, ta, rapper, today, forget, fuck, smokin,...   \n",
              "\n",
              "                                      lyrics_cleaned  \n",
              "0  cold chamber smoke kush gettin high plane swan...  \n",
              "1  public service announcement weezy baby best ra...  \n",
              "2  get ta rapper today forget fuck smokin brain c...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51a55529-5ee1-42c6-b30b-fc5d2ddeabeb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>artist_name</th>\n",
              "      <th>track_name</th>\n",
              "      <th>release_date</th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>len</th>\n",
              "      <th>valence</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>cleaned_stopwords</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>lyrics_lemmatized</th>\n",
              "      <th>lyrics_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13923</td>\n",
              "      <td>santana</td>\n",
              "      <td>wham!</td>\n",
              "      <td>1978</td>\n",
              "      <td>blues</td>\n",
              "      <td>cold chamber smoke kush gettin higher plane sw...</td>\n",
              "      <td>198</td>\n",
              "      <td>0.857791</td>\n",
              "      <td>[cold, chamber, smoke, kush, gettin, higher, p...</td>\n",
              "      <td>[cold, chamber, smoke, kush, gettin, higher, p...</td>\n",
              "      <td>[(cold, a), (chamber, n), (smoke, v), (kush, n...</td>\n",
              "      <td>[cold, chamber, smoke, kush, gettin, high, pla...</td>\n",
              "      <td>cold chamber smoke kush gettin high plane swan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14958</td>\n",
              "      <td>marvin sease</td>\n",
              "      <td>show me what you got</td>\n",
              "      <td>1991</td>\n",
              "      <td>blues</td>\n",
              "      <td>public service announcement weezy baby best ra...</td>\n",
              "      <td>198</td>\n",
              "      <td>0.794930</td>\n",
              "      <td>[public, service, announcement, weezy, baby, b...</td>\n",
              "      <td>[public, service, announcement, weezy, baby, b...</td>\n",
              "      <td>[(public, a), (service, n), (announcement, n),...</td>\n",
              "      <td>[public, service, announcement, weezy, baby, b...</td>\n",
              "      <td>public service announcement weezy baby best ra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15045</td>\n",
              "      <td>the robert cray band</td>\n",
              "      <td>1040 blues</td>\n",
              "      <td>1993</td>\n",
              "      <td>blues</td>\n",
              "      <td>gotta rapper today forget fuck smokin brain ce...</td>\n",
              "      <td>198</td>\n",
              "      <td>0.613561</td>\n",
              "      <td>[got, ta, rapper, today, forget, fuck, smokin,...</td>\n",
              "      <td>[got, ta, rapper, today, forget, fuck, smokin,...</td>\n",
              "      <td>[(got, v), (ta, a), (rapper, n), (today, n), (...</td>\n",
              "      <td>[get, ta, rapper, today, forget, fuck, smokin,...</td>\n",
              "      <td>get ta rapper today forget fuck smokin brain c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51a55529-5ee1-42c6-b30b-fc5d2ddeabeb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51a55529-5ee1-42c6-b30b-fc5d2ddeabeb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51a55529-5ee1-42c6-b30b-fc5d2ddeabeb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Encode label__"
      ],
      "metadata": {
        "id": "TgRLqHwsQ-zO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform valence to sentiment labels\n",
        "df['sentiment'] = df['valence'].apply(create_sentiment_from_valence)"
      ],
      "metadata": {
        "id": "4hPu3824Oe5D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Data splitting__"
      ],
      "metadata": {
        "id": "OtgZKPCHRJK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract labels \n",
        "y = df['sentiment']\n",
        "# Extract independent variables\n",
        "X = df['lyrics_cleaned']\n",
        "# Split data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify = y)\n",
        "# Create 3 cv for cross-validation \n",
        "cv = StratifiedKFold(n_splits=3, random_state=8, shuffle=True).split(X_train, y_train)"
      ],
      "metadata": {
        "id": "sj9aEs3hRKHg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Data exploration"
      ],
      "metadata": {
        "id": "pto_yzfB-0Wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Sentiment analysis "
      ],
      "metadata": {
        "id": "wVI55z7KtqnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 RandomForest"
      ],
      "metadata": {
        "id": "N20gw_aZuAgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Vectorization__"
      ],
      "metadata": {
        "id": "a_9ZROvn0RPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate CountVectorizer\n",
        "vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=0.2, max_df=0.7, max_features=100)\n",
        "# Learn a vocabulary dictionary of all tokens in the training set.\n",
        "vectorizer.fit(X_train)\n",
        "# Transform training set and testing set to document-term matrix.\n",
        "X_train_count_vectorized = vectorizer.transform(X_train)\n",
        "X_test_count_vectorized = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "T7UruBYv0FOa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate TfidfTransformer\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "# Learn vocabulary and idf from training set.\n",
        "tfidf_transformer.fit(X_train_count_vectorized)\n",
        "# Transform a train and set count matrix to a tf-idf representation.\n",
        "X_train_tfidf = tfidf_transformer.transform(X_train_count_vectorized)\n",
        "X_test_tfidf = tfidf_transformer.transform(X_test_count_vectorized)"
      ],
      "metadata": {
        "id": "Q5lUVxH30Ox6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Hyperparameter tuning (Grid search)__"
      ],
      "metadata": {
        "id": "g8d0Rs96IGWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf1 = RandomForestClassifier(random_state=8, n_estimators=50).fit(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "id": "MKcd-GXWMT61"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean([estimator.tree_.max_depth for estimator in rf1.estimators_])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmJqJjdCMXb8",
        "outputId": "5339df75-9dc7-4f6c-f2d6-8451dba17493"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54.14"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [40, 55, 60],\n",
        "    'min_samples_split': [2, 4, 8]\n",
        "    }\n",
        "hyperparams_grid"
      ],
      "metadata": {
        "id": "QKqD1MhzIOBk",
        "outputId": "fc3eaf63-103a-4815-99b7-a59bf8562c5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': [50, 100, 150],\n",
              " 'max_depth': [40, 55, 60],\n",
              " 'min_samples_split': [2, 4, 8]}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=8), hyperparams_grid, cv=3, verbose=2, scoring='accuracy')\n",
        "grid_search_rf.fit(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PPGlINPTKnGf",
        "outputId": "6c0ba1b3-3f78-4058-bd00-df9e8274ecc9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
            "[CV] END .max_depth=40, min_samples_split=2, n_estimators=50; total time=   1.9s\n",
            "[CV] END .max_depth=40, min_samples_split=2, n_estimators=50; total time=   2.0s\n",
            "[CV] END .max_depth=40, min_samples_split=2, n_estimators=50; total time=   2.0s\n",
            "[CV] END max_depth=40, min_samples_split=2, n_estimators=100; total time=   4.8s\n",
            "[CV] END max_depth=40, min_samples_split=2, n_estimators=100; total time=   3.9s\n",
            "[CV] END max_depth=40, min_samples_split=2, n_estimators=100; total time=   3.9s\n",
            "[CV] END max_depth=40, min_samples_split=2, n_estimators=150; total time=   6.8s\n",
            "[CV] END max_depth=40, min_samples_split=2, n_estimators=150; total time=   5.9s\n",
            "[CV] END max_depth=40, min_samples_split=2, n_estimators=150; total time=   6.8s\n",
            "[CV] END .max_depth=40, min_samples_split=4, n_estimators=50; total time=   1.9s\n",
            "[CV] END .max_depth=40, min_samples_split=4, n_estimators=50; total time=   1.9s\n",
            "[CV] END .max_depth=40, min_samples_split=4, n_estimators=50; total time=   1.8s\n",
            "[CV] END max_depth=40, min_samples_split=4, n_estimators=100; total time=   3.7s\n",
            "[CV] END max_depth=40, min_samples_split=4, n_estimators=100; total time=   4.6s\n",
            "[CV] END max_depth=40, min_samples_split=4, n_estimators=100; total time=   3.7s\n",
            "[CV] END max_depth=40, min_samples_split=4, n_estimators=150; total time=   5.5s\n",
            "[CV] END max_depth=40, min_samples_split=4, n_estimators=150; total time=   6.5s\n",
            "[CV] END max_depth=40, min_samples_split=4, n_estimators=150; total time=   5.6s\n",
            "[CV] END .max_depth=40, min_samples_split=8, n_estimators=50; total time=   1.8s\n",
            "[CV] END .max_depth=40, min_samples_split=8, n_estimators=50; total time=   2.1s\n",
            "[CV] END .max_depth=40, min_samples_split=8, n_estimators=50; total time=   2.3s\n",
            "[CV] END max_depth=40, min_samples_split=8, n_estimators=100; total time=   3.5s\n",
            "[CV] END max_depth=40, min_samples_split=8, n_estimators=100; total time=   3.5s\n",
            "[CV] END max_depth=40, min_samples_split=8, n_estimators=100; total time=   3.7s\n",
            "[CV] END max_depth=40, min_samples_split=8, n_estimators=150; total time=   6.0s\n",
            "[CV] END max_depth=40, min_samples_split=8, n_estimators=150; total time=   5.4s\n",
            "[CV] END max_depth=40, min_samples_split=8, n_estimators=150; total time=   6.2s\n",
            "[CV] END .max_depth=55, min_samples_split=2, n_estimators=50; total time=   2.0s\n",
            "[CV] END .max_depth=55, min_samples_split=2, n_estimators=50; total time=   2.0s\n",
            "[CV] END .max_depth=55, min_samples_split=2, n_estimators=50; total time=   1.9s\n",
            "[CV] END max_depth=55, min_samples_split=2, n_estimators=100; total time=   3.9s\n",
            "[CV] END max_depth=55, min_samples_split=2, n_estimators=100; total time=   4.9s\n",
            "[CV] END max_depth=55, min_samples_split=2, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=55, min_samples_split=2, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=55, min_samples_split=2, n_estimators=150; total time=   6.6s\n",
            "[CV] END max_depth=55, min_samples_split=2, n_estimators=150; total time=   6.0s\n",
            "[CV] END .max_depth=55, min_samples_split=4, n_estimators=50; total time=   2.4s\n",
            "[CV] END .max_depth=55, min_samples_split=4, n_estimators=50; total time=   2.3s\n",
            "[CV] END .max_depth=55, min_samples_split=4, n_estimators=50; total time=   1.9s\n",
            "[CV] END max_depth=55, min_samples_split=4, n_estimators=100; total time=   3.7s\n",
            "[CV] END max_depth=55, min_samples_split=4, n_estimators=100; total time=   3.9s\n",
            "[CV] END max_depth=55, min_samples_split=4, n_estimators=100; total time=   4.7s\n",
            "[CV] END max_depth=55, min_samples_split=4, n_estimators=150; total time=   5.6s\n",
            "[CV] END max_depth=55, min_samples_split=4, n_estimators=150; total time=   6.4s\n",
            "[CV] END max_depth=55, min_samples_split=4, n_estimators=150; total time=   5.9s\n",
            "[CV] END .max_depth=55, min_samples_split=8, n_estimators=50; total time=   1.8s\n",
            "[CV] END .max_depth=55, min_samples_split=8, n_estimators=50; total time=   1.8s\n",
            "[CV] END .max_depth=55, min_samples_split=8, n_estimators=50; total time=   1.9s\n",
            "[CV] END max_depth=55, min_samples_split=8, n_estimators=100; total time=   4.4s\n",
            "[CV] END max_depth=55, min_samples_split=8, n_estimators=100; total time=   3.7s\n",
            "[CV] END max_depth=55, min_samples_split=8, n_estimators=100; total time=   3.6s\n",
            "[CV] END max_depth=55, min_samples_split=8, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=55, min_samples_split=8, n_estimators=150; total time=   5.5s\n",
            "[CV] END max_depth=55, min_samples_split=8, n_estimators=150; total time=   5.8s\n",
            "[CV] END .max_depth=60, min_samples_split=2, n_estimators=50; total time=   2.5s\n",
            "[CV] END .max_depth=60, min_samples_split=2, n_estimators=50; total time=   2.0s\n",
            "[CV] END .max_depth=60, min_samples_split=2, n_estimators=50; total time=   2.1s\n",
            "[CV] END max_depth=60, min_samples_split=2, n_estimators=100; total time=   3.9s\n",
            "[CV] END max_depth=60, min_samples_split=2, n_estimators=100; total time=   4.7s\n",
            "[CV] END max_depth=60, min_samples_split=2, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=60, min_samples_split=2, n_estimators=150; total time=   5.9s\n",
            "[CV] END max_depth=60, min_samples_split=2, n_estimators=150; total time=   7.0s\n",
            "[CV] END max_depth=60, min_samples_split=2, n_estimators=150; total time=   6.0s\n",
            "[CV] END .max_depth=60, min_samples_split=4, n_estimators=50; total time=   1.9s\n",
            "[CV] END .max_depth=60, min_samples_split=4, n_estimators=50; total time=   2.5s\n",
            "[CV] END .max_depth=60, min_samples_split=4, n_estimators=50; total time=   2.2s\n",
            "[CV] END max_depth=60, min_samples_split=4, n_estimators=100; total time=   3.8s\n",
            "[CV] END max_depth=60, min_samples_split=4, n_estimators=100; total time=   3.8s\n",
            "[CV] END max_depth=60, min_samples_split=4, n_estimators=100; total time=   4.5s\n",
            "[CV] END max_depth=60, min_samples_split=4, n_estimators=150; total time=   5.9s\n",
            "[CV] END max_depth=60, min_samples_split=4, n_estimators=150; total time=   5.8s\n",
            "[CV] END max_depth=60, min_samples_split=4, n_estimators=150; total time=   6.4s\n",
            "[CV] END .max_depth=60, min_samples_split=8, n_estimators=50; total time=   1.8s\n",
            "[CV] END .max_depth=60, min_samples_split=8, n_estimators=50; total time=   1.9s\n",
            "[CV] END .max_depth=60, min_samples_split=8, n_estimators=50; total time=   1.8s\n",
            "[CV] END max_depth=60, min_samples_split=8, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=60, min_samples_split=8, n_estimators=100; total time=   3.9s\n",
            "[CV] END max_depth=60, min_samples_split=8, n_estimators=100; total time=   3.6s\n",
            "[CV] END max_depth=60, min_samples_split=8, n_estimators=150; total time=   5.8s\n",
            "[CV] END max_depth=60, min_samples_split=8, n_estimators=150; total time=   5.9s\n",
            "[CV] END max_depth=60, min_samples_split=8, n_estimators=150; total time=   5.4s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=8),\n",
              "             param_grid={'max_depth': [40, 55, 60],\n",
              "                         'min_samples_split': [2, 4, 8],\n",
              "                         'n_estimators': [50, 100, 150]},\n",
              "             scoring='accuracy', verbose=2)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=8),\n",
              "             param_grid={&#x27;max_depth&#x27;: [40, 55, 60],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 4, 8],\n",
              "                         &#x27;n_estimators&#x27;: [50, 100, 150]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=8),\n",
              "             param_grid={&#x27;max_depth&#x27;: [40, 55, 60],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 4, 8],\n",
              "                         &#x27;n_estimators&#x27;: [50, 100, 150]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=8)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=8)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = grid_search_rf.best_params_\n",
        "best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z7SwrN4IOMV",
        "outputId": "5921d374-261d-425f-944a-6a0708f52f68"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 55, 'min_samples_split': 8, 'n_estimators': 150}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_rf.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2T0Uvg8S99t",
        "outputId": "099ed0d7-e2be-4a1e-ea1e-81bd7aeef58d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.544696330148704"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Assessment on test set__"
      ],
      "metadata": {
        "id": "VNldb7rcIGap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_best = RandomForestClassifier(random_state=8, max_depth=best_params['max_depth'], min_samples_split=best_params['min_samples_split'], n_estimators=best_params['n_estimators']).fit(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "id": "me3-csSeIO1Y"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_preds = rf_best.predict(X_test_tfidf)"
      ],
      "metadata": {
        "id": "hbv0N-dTIO4g"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test_preds, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e5vqEaPIO7L",
        "outputId": "51bfe938-0c9a-412b-985b-b5bb5c97198e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.547245409015025"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 LTSM"
      ],
      "metadata": {
        "id": "tl8Vwoy9uV1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Split training set into another training set and validation set__"
      ],
      "metadata": {
        "id": "qzjwMA8JK65g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_2, X_val, y_train_2, y_val = train_test_split(X_train, y_train, random_state=42, stratify = y_train)"
      ],
      "metadata": {
        "id": "KJlbMAu8ZQTG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Vectorization__"
      ],
      "metadata": {
        "id": "Dwymy2e_psXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the length of our vocabulary\n",
        "word_tokenizer = Tokenizer()\n",
        "\n",
        "# Create a dict of word and index from the list of sentences. Required before texts_to_sequences\n",
        "word_tokenizer.fit_on_texts(X_train_2)\n",
        "\n",
        "vocab_length = len(word_tokenizer.word_index) + 1\n",
        "vocab_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uumF0TgiVbsD",
        "outputId": "d4cba64a-0486-4353-bf08-402329e42c38"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29711"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences\n",
        "longest_train_lyrics = max(X_train_2, key=lambda sentence: len(word_tokenize(sentence)))\n",
        "length_long_sentence = len(word_tokenize(longest_train_lyrics))\n",
        "\n",
        "# texts_to_sequences: Transforms each text in texts to a sequence of integers (integers = index of word by fit_on_texts)\n",
        "padded_train_lyrics = pad_sequences(\n",
        "    word_tokenizer.texts_to_sequences(X_train_2),\n",
        "    length_long_sentence, \n",
        "    padding='post'\n",
        ")\n",
        "\n",
        "padded_val_lyrics = pad_sequences(\n",
        "    word_tokenizer.texts_to_sequences(X_val),\n",
        "    length_long_sentence, \n",
        "    padding='post'\n",
        ")\n",
        "\n",
        "padded_test_lyrics = pad_sequences(\n",
        "    word_tokenizer.texts_to_sequences(X_test),\n",
        "    length_long_sentence, \n",
        "    padding='post'\n",
        ")"
      ],
      "metadata": {
        "id": "WfDNNjvMVbzT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Manual Hyperparameter Tuning__"
      ],
      "metadata": {
        "id": "H6nZsus_pztE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(prediction):\n",
        "  prediction2 = []\n",
        "  for i in prediction:\n",
        "    max_value = max(i)\n",
        "    prediction2.append(list(i).index(max_value))\n",
        "\n",
        "  return accuracy_score(prediction2, y_val)"
      ],
      "metadata": {
        "id": "eafJAMsiTCch"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(vector_size, lstm_layers, dense_layers, learning_rate):\n",
        "    with tf.device(device_name):\n",
        "      model = Sequential()\n",
        "      # embedding\n",
        "      model.add(\n",
        "          Embedding(input_dim=vocab_length,\n",
        "                    output_dim=vector_size,\n",
        "                    input_length=length_long_sentence))\n",
        "\n",
        "      # add lstm layers\n",
        "      for lstm_layer in lstm_layers:\n",
        "        if lstm_layer['regularized'] != None:\n",
        "          model.add(LSTM(lstm_layer['unit'], return_sequences=lstm_layer['return_sequences'], kernel_regularizer=regularizers.l2(lstm_layer['regularized'])))\n",
        "        else:\n",
        "          model.add(LSTM(lstm_layer['unit'], return_sequences=lstm_layer['return_sequences']))\n",
        "        \n",
        "        # add dropout\n",
        "        if lstm_layer['dropout'] != None:\n",
        "          model.add(Dropout(lstm_layer['dropout']))\n",
        "\n",
        "      # add dense layers\n",
        "      for dense_layer in dense_layers: \n",
        "        model.add(Dense(dense_layer['unit'], activation=dense_layer['activation']))\n",
        "      \n",
        "      # compile\n",
        "      model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "      return model"
      ],
      "metadata": {
        "id": "Ps0oYy9JTXOV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trial 1: Accuracy - 0.8915\n",
        "lstm_layers = [{'unit': 50, 'return_sequences': False, 'dropout': None, 'regularized': None}]\n",
        "dense_layers = [{'unit': 3, 'activation': 'softmax'}]\n",
        "model1 = model_builder(100, lstm_layers, dense_layers, 0.001)\n",
        "model1.fit(padded_train_lyrics, y_train_2, batch_size = 256, epochs = 50)"
      ],
      "metadata": {
        "id": "8-l5kiOdH9Ck",
        "outputId": "5fc9f282-ca0d-40aa-b1de-48b2fb0299fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "27/27 [==============================] - 10s 267ms/step - loss: 0.9874 - accuracy: 0.5301\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 5s 199ms/step - loss: 0.9545 - accuracy: 0.5456\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.9547 - accuracy: 0.5456\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 5s 202ms/step - loss: 0.9558 - accuracy: 0.5456\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 6s 232ms/step - loss: 0.9548 - accuracy: 0.5456\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 6s 204ms/step - loss: 0.9543 - accuracy: 0.5456\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 5s 191ms/step - loss: 0.9542 - accuracy: 0.5456\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 5s 197ms/step - loss: 0.9547 - accuracy: 0.5456\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 5s 167ms/step - loss: 0.9555 - accuracy: 0.5456\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.9549 - accuracy: 0.5456\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 6s 230ms/step - loss: 0.9548 - accuracy: 0.5456\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.9544 - accuracy: 0.5456\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 4s 161ms/step - loss: 0.9546 - accuracy: 0.5456\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 4s 131ms/step - loss: 0.9546 - accuracy: 0.5456\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 3s 103ms/step - loss: 0.9540 - accuracy: 0.5456\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 4s 165ms/step - loss: 0.9541 - accuracy: 0.5456\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.9543 - accuracy: 0.5456\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 5s 183ms/step - loss: 0.9542 - accuracy: 0.5456\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 4s 128ms/step - loss: 0.9547 - accuracy: 0.5456\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - 2s 94ms/step - loss: 0.9546 - accuracy: 0.5456\n",
            "Epoch 21/50\n",
            "27/27 [==============================] - 3s 110ms/step - loss: 0.9551 - accuracy: 0.5456\n",
            "Epoch 22/50\n",
            "27/27 [==============================] - 5s 173ms/step - loss: 0.9544 - accuracy: 0.5456\n",
            "Epoch 23/50\n",
            "27/27 [==============================] - 2s 95ms/step - loss: 0.9541 - accuracy: 0.5456\n",
            "Epoch 24/50\n",
            "27/27 [==============================] - 3s 109ms/step - loss: 0.9540 - accuracy: 0.5456\n",
            "Epoch 25/50\n",
            "27/27 [==============================] - 3s 120ms/step - loss: 0.9542 - accuracy: 0.5456\n",
            "Epoch 26/50\n",
            "27/27 [==============================] - 3s 122ms/step - loss: 0.9546 - accuracy: 0.5456\n",
            "Epoch 27/50\n",
            "27/27 [==============================] - 4s 144ms/step - loss: 0.9545 - accuracy: 0.5456\n",
            "Epoch 28/50\n",
            "27/27 [==============================] - 2s 89ms/step - loss: 0.9545 - accuracy: 0.5456\n",
            "Epoch 29/50\n",
            "27/27 [==============================] - 3s 97ms/step - loss: 0.9541 - accuracy: 0.5456\n",
            "Epoch 30/50\n",
            "27/27 [==============================] - 5s 175ms/step - loss: 0.9541 - accuracy: 0.5456\n",
            "Epoch 31/50\n",
            "27/27 [==============================] - 3s 96ms/step - loss: 0.9546 - accuracy: 0.5456\n",
            "Epoch 32/50\n",
            "27/27 [==============================] - 3s 100ms/step - loss: 0.9538 - accuracy: 0.5456\n",
            "Epoch 33/50\n",
            "27/27 [==============================] - 2s 82ms/step - loss: 0.9540 - accuracy: 0.5456\n",
            "Epoch 34/50\n",
            "27/27 [==============================] - 3s 92ms/step - loss: 0.9543 - accuracy: 0.5456\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - 3s 101ms/step - loss: 0.9539 - accuracy: 0.5456\n",
            "Epoch 36/50\n",
            "27/27 [==============================] - 3s 106ms/step - loss: 0.9553 - accuracy: 0.5456\n",
            "Epoch 37/50\n",
            "27/27 [==============================] - 2s 65ms/step - loss: 0.9549 - accuracy: 0.5456\n",
            "Epoch 38/50\n",
            "27/27 [==============================] - 2s 62ms/step - loss: 0.9539 - accuracy: 0.5456\n",
            "Epoch 39/50\n",
            "27/27 [==============================] - 1s 54ms/step - loss: 0.9540 - accuracy: 0.5456\n",
            "Epoch 40/50\n",
            "27/27 [==============================] - 2s 75ms/step - loss: 0.9540 - accuracy: 0.5456\n",
            "Epoch 41/50\n",
            "27/27 [==============================] - 1s 47ms/step - loss: 0.9540 - accuracy: 0.5456\n",
            "Epoch 42/50\n",
            "27/27 [==============================] - 2s 94ms/step - loss: 0.9541 - accuracy: 0.5456\n",
            "Epoch 43/50\n",
            "27/27 [==============================] - 2s 91ms/step - loss: 0.9538 - accuracy: 0.5456\n",
            "Epoch 44/50\n",
            "27/27 [==============================] - 2s 82ms/step - loss: 0.9534 - accuracy: 0.5456\n",
            "Epoch 45/50\n",
            "27/27 [==============================] - 3s 96ms/step - loss: 0.9566 - accuracy: 0.5422\n",
            "Epoch 46/50\n",
            "27/27 [==============================] - 2s 94ms/step - loss: 0.9539 - accuracy: 0.5456\n",
            "Epoch 47/50\n",
            "27/27 [==============================] - 4s 172ms/step - loss: 0.9541 - accuracy: 0.5456\n",
            "Epoch 48/50\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 0.9543 - accuracy: 0.5456\n",
            "Epoch 49/50\n",
            "27/27 [==============================] - 4s 151ms/step - loss: 0.9552 - accuracy: 0.5456\n",
            "Epoch 50/50\n",
            "27/27 [==============================] - 1s 52ms/step - loss: 0.9536 - accuracy: 0.5456\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f927afe1180>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trial 1: Val accuracy - 0.4452\n",
        "prediction1 = model1.predict(padded_val_lyrics)\n",
        "calculate_accuracy(prediction1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpXWIz7wbZrX",
        "outputId": "e65a50e5-f7c2-48de-eac9-479d04d1e81c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5458593054318789"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trial 2: Accuracy - 0.5456\n",
        "lstm_layers = [{'unit': 50, 'return_sequences': False, 'dropout': 0.2, 'regularized': None}]\n",
        "dense_layers = [{'unit': 3, 'activation': 'softmax'}]\n",
        "model2 = model_builder(100, lstm_layers, dense_layers, 0.001)\n",
        "model2.fit(padded_train_lyrics, y_train_2, batch_size = 256, epochs = 50)"
      ],
      "metadata": {
        "id": "5fBgR0VXS0yy",
        "outputId": "81078d77-625a-4f50-9dc4-ee7fec095e91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "27/27 [==============================] - 8s 216ms/step - loss: 0.9923 - accuracy: 0.5278\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 5s 170ms/step - loss: 0.9588 - accuracy: 0.5455\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 5s 189ms/step - loss: 0.9576 - accuracy: 0.5456\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 6s 202ms/step - loss: 0.9558 - accuracy: 0.5456\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 4s 154ms/step - loss: 0.9552 - accuracy: 0.5456\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 5s 172ms/step - loss: 0.9575 - accuracy: 0.5456\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 4s 151ms/step - loss: 0.9567 - accuracy: 0.5456\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 4s 130ms/step - loss: 0.9547 - accuracy: 0.5456\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 4s 149ms/step - loss: 0.9561 - accuracy: 0.5456\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 5s 199ms/step - loss: 0.9559 - accuracy: 0.5456\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 3s 124ms/step - loss: 0.9576 - accuracy: 0.5456\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 3s 106ms/step - loss: 0.9560 - accuracy: 0.5456\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 4s 151ms/step - loss: 0.9578 - accuracy: 0.5456\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 3s 118ms/step - loss: 0.9574 - accuracy: 0.5456\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 3s 124ms/step - loss: 0.9558 - accuracy: 0.5456\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 3s 100ms/step - loss: 0.9557 - accuracy: 0.5456\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 4s 157ms/step - loss: 0.9550 - accuracy: 0.5456\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 4s 155ms/step - loss: 0.9555 - accuracy: 0.5456\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 3s 107ms/step - loss: 0.9554 - accuracy: 0.5456\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - 3s 105ms/step - loss: 0.9562 - accuracy: 0.5456\n",
            "Epoch 21/50\n",
            "27/27 [==============================] - 2s 73ms/step - loss: 0.9553 - accuracy: 0.5456\n",
            "Epoch 22/50\n",
            "27/27 [==============================] - 3s 127ms/step - loss: 0.9554 - accuracy: 0.5456\n",
            "Epoch 23/50\n",
            "27/27 [==============================] - 3s 110ms/step - loss: 0.9555 - accuracy: 0.5456\n",
            "Epoch 24/50\n",
            "27/27 [==============================] - 2s 64ms/step - loss: 0.9552 - accuracy: 0.5456\n",
            "Epoch 25/50\n",
            "27/27 [==============================] - 2s 61ms/step - loss: 0.9556 - accuracy: 0.5456\n",
            "Epoch 26/50\n",
            "27/27 [==============================] - 2s 77ms/step - loss: 0.9545 - accuracy: 0.5456\n",
            "Epoch 27/50\n",
            "27/27 [==============================] - 3s 103ms/step - loss: 0.9558 - accuracy: 0.5456\n",
            "Epoch 28/50\n",
            "27/27 [==============================] - 4s 151ms/step - loss: 0.9561 - accuracy: 0.5456\n",
            "Epoch 29/50\n",
            "27/27 [==============================] - 2s 78ms/step - loss: 0.9563 - accuracy: 0.5456\n",
            "Epoch 30/50\n",
            "27/27 [==============================] - 2s 76ms/step - loss: 0.9556 - accuracy: 0.5456\n",
            "Epoch 31/50\n",
            "27/27 [==============================] - 2s 62ms/step - loss: 0.9560 - accuracy: 0.5456\n",
            "Epoch 32/50\n",
            "27/27 [==============================] - 2s 71ms/step - loss: 0.9550 - accuracy: 0.5456\n",
            "Epoch 33/50\n",
            "27/27 [==============================] - 2s 78ms/step - loss: 0.9544 - accuracy: 0.5456\n",
            "Epoch 34/50\n",
            "27/27 [==============================] - 4s 148ms/step - loss: 0.9555 - accuracy: 0.5456\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - 2s 82ms/step - loss: 0.9562 - accuracy: 0.5456\n",
            "Epoch 36/50\n",
            "27/27 [==============================] - 2s 81ms/step - loss: 0.9558 - accuracy: 0.5456\n",
            "Epoch 37/50\n",
            "27/27 [==============================] - 3s 92ms/step - loss: 0.9550 - accuracy: 0.5456\n",
            "Epoch 38/50\n",
            "27/27 [==============================] - 3s 97ms/step - loss: 0.9558 - accuracy: 0.5456\n",
            "Epoch 39/50\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.9555 - accuracy: 0.5456\n",
            "Epoch 40/50\n",
            "27/27 [==============================] - 2s 69ms/step - loss: 0.9543 - accuracy: 0.5456\n",
            "Epoch 41/50\n",
            "27/27 [==============================] - 2s 73ms/step - loss: 0.9546 - accuracy: 0.5456\n",
            "Epoch 42/50\n",
            "27/27 [==============================] - 1s 57ms/step - loss: 0.9550 - accuracy: 0.5456\n",
            "Epoch 43/50\n",
            "27/27 [==============================] - 2s 63ms/step - loss: 0.9548 - accuracy: 0.5456\n",
            "Epoch 44/50\n",
            "27/27 [==============================] - 1s 45ms/step - loss: 0.9562 - accuracy: 0.5456\n",
            "Epoch 45/50\n",
            "27/27 [==============================] - 1s 33ms/step - loss: 0.9549 - accuracy: 0.5456\n",
            "Epoch 46/50\n",
            "27/27 [==============================] - 2s 73ms/step - loss: 0.9545 - accuracy: 0.5456\n",
            "Epoch 47/50\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.9547 - accuracy: 0.5456\n",
            "Epoch 48/50\n",
            "27/27 [==============================] - 2s 71ms/step - loss: 0.9525 - accuracy: 0.5456\n",
            "Epoch 49/50\n",
            "27/27 [==============================] - 2s 68ms/step - loss: 0.9497 - accuracy: 0.5456\n",
            "Epoch 50/50\n",
            "27/27 [==============================] - 2s 86ms/step - loss: 0.9506 - accuracy: 0.5456\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f927e89b370>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trial 2: Val accuracy - 0.5458\n",
        "prediction2 = model2.predict(padded_val_lyrics)\n",
        "calculate_accuracy(prediction2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GssewZm4S0LD",
        "outputId": "a2b4dc3c-177b-4b54-e9d7-0f50d99422d1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 1s 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5458593054318789"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trial 3: Accuracy - 0.5456\n",
        "lstm_layers = [{'unit': 50, 'return_sequences': False, 'dropout': None, 'regularized': 0.01}]\n",
        "dense_layers = [{'unit': 3, 'activation': 'softmax'}]\n",
        "model3 = model_builder(100, lstm_layers, dense_layers, 0.001)\n",
        "model3.fit(padded_train_lyrics, y_train_2, batch_size = 256, epochs = 50)"
      ],
      "metadata": {
        "id": "HrmL98pKAfo8",
        "outputId": "1a841ec6-2ef4-490a-a0d5-231d334e751a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "27/27 [==============================] - 7s 167ms/step - loss: 2.0304 - accuracy: 0.5237\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 5s 180ms/step - loss: 1.5067 - accuracy: 0.5456\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 5s 179ms/step - loss: 1.2331 - accuracy: 0.5456\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 4s 152ms/step - loss: 1.0893 - accuracy: 0.5456\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 4s 169ms/step - loss: 1.0165 - accuracy: 0.5456\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 4s 149ms/step - loss: 0.9818 - accuracy: 0.5456\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 4s 130ms/step - loss: 0.9672 - accuracy: 0.5456\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 3s 125ms/step - loss: 0.9603 - accuracy: 0.5456\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 4s 148ms/step - loss: 0.9572 - accuracy: 0.5456\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 3s 116ms/step - loss: 0.9552 - accuracy: 0.5456\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 3s 106ms/step - loss: 0.9549 - accuracy: 0.5456\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 3s 98ms/step - loss: 0.9549 - accuracy: 0.5456\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.9545 - accuracy: 0.5456\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 4s 145ms/step - loss: 0.9551 - accuracy: 0.5456\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 3s 102ms/step - loss: 0.9544 - accuracy: 0.5456\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 3s 104ms/step - loss: 0.9545 - accuracy: 0.5456\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 2s 82ms/step - loss: 0.9549 - accuracy: 0.5456\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 4s 158ms/step - loss: 0.9545 - accuracy: 0.5456\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 2s 89ms/step - loss: 0.9552 - accuracy: 0.5456\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - 2s 80ms/step - loss: 0.9544 - accuracy: 0.5456\n",
            "Epoch 21/50\n",
            "27/27 [==============================] - 2s 77ms/step - loss: 0.9541 - accuracy: 0.5456\n",
            "Epoch 22/50\n",
            "27/27 [==============================] - 3s 92ms/step - loss: 0.9543 - accuracy: 0.5456\n",
            "Epoch 23/50\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.9538 - accuracy: 0.5456\n",
            "Epoch 24/50\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.9543 - accuracy: 0.5456\n",
            "Epoch 25/50\n",
            "27/27 [==============================] - 2s 74ms/step - loss: 0.9548 - accuracy: 0.5456\n",
            "Epoch 26/50\n",
            "27/27 [==============================] - 1s 55ms/step - loss: 0.9544 - accuracy: 0.5456\n",
            "Epoch 27/50\n",
            "27/27 [==============================] - 2s 82ms/step - loss: 0.9539 - accuracy: 0.5456\n",
            "Epoch 28/50\n",
            "27/27 [==============================] - 2s 79ms/step - loss: 0.9537 - accuracy: 0.5456\n",
            "Epoch 29/50\n",
            "27/27 [==============================] - 3s 100ms/step - loss: 0.9545 - accuracy: 0.5456\n",
            "Epoch 30/50\n",
            "27/27 [==============================] - 2s 85ms/step - loss: 0.9541 - accuracy: 0.5456\n",
            "Epoch 31/50\n",
            "27/27 [==============================] - 2s 69ms/step - loss: 0.9543 - accuracy: 0.5456\n",
            "Epoch 32/50\n",
            "27/27 [==============================] - 2s 81ms/step - loss: 0.9539 - accuracy: 0.5456\n",
            "Epoch 33/50\n",
            "27/27 [==============================] - 2s 63ms/step - loss: 0.9542 - accuracy: 0.5456\n",
            "Epoch 34/50\n",
            "27/27 [==============================] - 1s 49ms/step - loss: 0.9539 - accuracy: 0.5456\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - 3s 94ms/step - loss: 0.9539 - accuracy: 0.5456\n",
            "Epoch 36/50\n",
            "27/27 [==============================] - 3s 93ms/step - loss: 0.9540 - accuracy: 0.5456\n",
            "Epoch 37/50\n",
            "27/27 [==============================] - 2s 73ms/step - loss: 0.9538 - accuracy: 0.5456\n",
            "Epoch 38/50\n",
            "27/27 [==============================] - 2s 58ms/step - loss: 0.9537 - accuracy: 0.5456\n",
            "Epoch 39/50\n",
            "27/27 [==============================] - 2s 60ms/step - loss: 0.9539 - accuracy: 0.5456\n",
            "Epoch 40/50\n",
            "27/27 [==============================] - 1s 46ms/step - loss: 0.9540 - accuracy: 0.5456\n",
            "Epoch 41/50\n",
            "27/27 [==============================] - 2s 65ms/step - loss: 0.9544 - accuracy: 0.5456\n",
            "Epoch 42/50\n",
            "27/27 [==============================] - 2s 65ms/step - loss: 0.9541 - accuracy: 0.5456\n",
            "Epoch 43/50\n",
            "27/27 [==============================] - 2s 80ms/step - loss: 0.9558 - accuracy: 0.5456\n",
            "Epoch 44/50\n",
            "27/27 [==============================] - 2s 68ms/step - loss: 0.9541 - accuracy: 0.5456\n",
            "Epoch 45/50\n",
            "27/27 [==============================] - 2s 73ms/step - loss: 0.9542 - accuracy: 0.5456\n",
            "Epoch 46/50\n",
            "27/27 [==============================] - 2s 72ms/step - loss: 0.9540 - accuracy: 0.5456\n",
            "Epoch 47/50\n",
            "27/27 [==============================] - 2s 57ms/step - loss: 0.9538 - accuracy: 0.5456\n",
            "Epoch 48/50\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.9546 - accuracy: 0.5456\n",
            "Epoch 49/50\n",
            "27/27 [==============================] - 2s 80ms/step - loss: 0.9541 - accuracy: 0.5456\n",
            "Epoch 50/50\n",
            "27/27 [==============================] - 3s 106ms/step - loss: 0.9540 - accuracy: 0.5456\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f932b82ecb0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trial 3: Val accuracy - 0.5458\n",
        "prediction3 = model3.predict(padded_val_lyrics)\n",
        "calculate_accuracy(prediction3)"
      ],
      "metadata": {
        "id": "o0PZMHewNaI2",
        "outputId": "fa7f4d4f-8b04-45cc-b7e7-6cc83ab3e28b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5458593054318789"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__RandomSearch Hyperparameter Tuning__"
      ],
      "metadata": {
        "id": "j06Wo7TTNsAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyHyperModel(kt.HyperModel):\n",
        "    def build(self, hp):\n",
        "      with tf.device(device_name):\n",
        "        model = Sequential()\n",
        "        # embedding\n",
        "        hp_vector_size = hp.Int('vector_size', \n",
        "                                min_value=100, \n",
        "                                max_value=200, \n",
        "                                step=50)\n",
        "        model.add(\n",
        "            Embedding(input_dim=vocab_length,\n",
        "                      output_dim=hp_vector_size,\n",
        "                      input_length=length_long_sentence))\n",
        "\n",
        "        # first lstm\n",
        "        hp_lstm_units1 = hp.Int('lstm_units1', \n",
        "                                min_value=32, \n",
        "                                max_value=128, \n",
        "                                step=32)\n",
        "        model.add(LSTM(hp_lstm_units1, return_sequences=True, kernel_initializer=\"glorot_uniform\"))\n",
        "\n",
        "        # drop out\n",
        "        hp_dropout_rate = hp.Float('dropout_rate', \n",
        "                                  min_value=0.0, \n",
        "                                  max_value=0.4, \n",
        "                                  step=0.1)\n",
        "        model.add(Dropout(hp_dropout_rate))\n",
        "\n",
        "        # second lstm\n",
        "        hp_lstm_units2 = hp.Int('lstm_units2', \n",
        "                                min_value=32, \n",
        "                                max_value=128, \n",
        "                                step=32)\n",
        "        model.add(LSTM(hp_lstm_units2, kernel_regularizer=regularizers.l2(0.01), kernel_initializer=\"glorot_uniform\"))\n",
        "\n",
        "        # dense layer\n",
        "        model.add(Dense(3,activation='softmax'))\n",
        "        \n",
        "        # compile\n",
        "        hp_learning_rate = hp.Choice('learning_rate', \n",
        "                                    values=[1e-3, 1e-4])\n",
        "        model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, *args, **kwargs):\n",
        "        return model.fit(\n",
        "            *args,\n",
        "            batch_size=hp.Choice(\"batch_size\", [256, 512]),\n",
        "            **kwargs,\n",
        "        )"
      ],
      "metadata": {
        "id": "wmJZystdgNWa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.RandomSearch(\n",
        "    MyHyperModel(),\n",
        "    objective=kt.Objective(\"val_accuracy\", direction=\"max\"),\n",
        "    max_trials=20,\n",
        "    # overwrite=True,\n",
        "    project_name=\"tune_hypermodel\",\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "id": "wysHhasjgPdV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stop_early = EarlyStopping(monitor='loss', patience=5)\n",
        "\n",
        "# random search \n",
        "tuner.search(padded_train_lyrics, \n",
        "             y_train_2, \n",
        "             verbose = 2,\n",
        "             epochs=40,\n",
        "             validation_data=(padded_val_lyrics, y_val)\n",
        "            #  callbacks=[stop_early]       \n",
        "             )\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxoOXOyYgTkt",
        "outputId": "b054f2d9-f1d2-45ad-f250-e88a6748c752"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 03m 26s]\n",
            "val_accuracy: 0.5458592772483826\n",
            "\n",
            "Best val_accuracy So Far: 0.5463045239448547\n",
            "Total elapsed time: 00h 31m 26s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_hps.get('vector_size'))\n",
        "print(best_hps.get('lstm_units1'))\n",
        "print(best_hps.get('dropout_rate'))\n",
        "print(best_hps.get('lstm_units2'))\n",
        "print(best_hps.get('learning_rate'))\n",
        "print(best_hps.get('batch_size'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzUs9GpDyDST",
        "outputId": "2460e3f3-62ac-4317-9e2c-f7739a803d71"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150\n",
            "128\n",
            "0.0\n",
            "128\n",
            "0.001\n",
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_best = tuner.hypermodel.build(best_hps)\n",
        "history = model_best.fit(padded_train_lyrics, y_train_2, epochs=100, batch_size=best_hps.get('batch_size'), validation_data=(padded_val_lyrics, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA-K7jxWjP7x",
        "outputId": "a7fc7e57-ed27-4e6a-badb-68d5111135d1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 8s 293ms/step - loss: 2.7105 - accuracy: 0.5274 - val_loss: 2.2885 - val_accuracy: 0.5459\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 4s 261ms/step - loss: 2.0416 - accuracy: 0.5456 - val_loss: 1.7661 - val_accuracy: 0.5459\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 3s 217ms/step - loss: 1.6076 - accuracy: 0.5456 - val_loss: 1.4328 - val_accuracy: 0.5459\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 3s 217ms/step - loss: 1.3347 - accuracy: 0.5456 - val_loss: 1.2268 - val_accuracy: 0.5459\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 3s 222ms/step - loss: 1.1667 - accuracy: 0.5456 - val_loss: 1.1027 - val_accuracy: 0.5459\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 4s 263ms/step - loss: 1.0694 - accuracy: 0.5456 - val_loss: 1.0335 - val_accuracy: 0.5459\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 3s 201ms/step - loss: 1.0170 - accuracy: 0.5456 - val_loss: 0.9966 - val_accuracy: 0.5459\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 3s 204ms/step - loss: 0.9866 - accuracy: 0.5456 - val_loss: 0.9771 - val_accuracy: 0.5459\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 3s 194ms/step - loss: 0.9716 - accuracy: 0.5456 - val_loss: 0.9724 - val_accuracy: 0.5459\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 4s 276ms/step - loss: 0.9650 - accuracy: 0.5456 - val_loss: 0.9603 - val_accuracy: 0.5459\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 3s 225ms/step - loss: 0.9616 - accuracy: 0.5456 - val_loss: 0.9573 - val_accuracy: 0.5459\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 3s 213ms/step - loss: 0.9592 - accuracy: 0.5456 - val_loss: 0.9578 - val_accuracy: 0.5459\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 3s 221ms/step - loss: 0.9563 - accuracy: 0.5456 - val_loss: 0.9551 - val_accuracy: 0.5459\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 3s 218ms/step - loss: 0.9568 - accuracy: 0.5456 - val_loss: 0.9572 - val_accuracy: 0.5459\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 4s 268ms/step - loss: 0.9551 - accuracy: 0.5456 - val_loss: 0.9546 - val_accuracy: 0.5459\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 3s 212ms/step - loss: 0.9552 - accuracy: 0.5456 - val_loss: 0.9547 - val_accuracy: 0.5459\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 3s 199ms/step - loss: 0.9548 - accuracy: 0.5456 - val_loss: 0.9544 - val_accuracy: 0.5459\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 3s 213ms/step - loss: 0.9543 - accuracy: 0.5456 - val_loss: 0.9541 - val_accuracy: 0.5459\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 4s 271ms/step - loss: 0.9545 - accuracy: 0.5456 - val_loss: 0.9544 - val_accuracy: 0.5459\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 3s 179ms/step - loss: 0.9539 - accuracy: 0.5456 - val_loss: 0.9543 - val_accuracy: 0.5459\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 3s 198ms/step - loss: 0.9545 - accuracy: 0.5456 - val_loss: 0.9538 - val_accuracy: 0.5459\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 3s 194ms/step - loss: 0.9542 - accuracy: 0.5456 - val_loss: 0.9555 - val_accuracy: 0.5459\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 3s 242ms/step - loss: 0.9552 - accuracy: 0.5456 - val_loss: 0.9560 - val_accuracy: 0.5459\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 3s 216ms/step - loss: 0.9547 - accuracy: 0.5456 - val_loss: 0.9538 - val_accuracy: 0.5459\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 2s 149ms/step - loss: 0.9548 - accuracy: 0.5456 - val_loss: 0.9547 - val_accuracy: 0.5459\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 2s 178ms/step - loss: 0.9547 - accuracy: 0.5456 - val_loss: 0.9541 - val_accuracy: 0.5459\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 2s 169ms/step - loss: 0.9542 - accuracy: 0.5456 - val_loss: 0.9539 - val_accuracy: 0.5459\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 3s 234ms/step - loss: 0.9545 - accuracy: 0.5456 - val_loss: 0.9542 - val_accuracy: 0.5459\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 4s 285ms/step - loss: 0.9567 - accuracy: 0.5456 - val_loss: 0.9585 - val_accuracy: 0.5459\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 3s 192ms/step - loss: 0.9552 - accuracy: 0.5456 - val_loss: 0.9543 - val_accuracy: 0.5459\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 2s 185ms/step - loss: 0.9540 - accuracy: 0.5456 - val_loss: 0.9539 - val_accuracy: 0.5459\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 3s 188ms/step - loss: 0.9546 - accuracy: 0.5456 - val_loss: 0.9546 - val_accuracy: 0.5459\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 4s 267ms/step - loss: 0.9542 - accuracy: 0.5456 - val_loss: 0.9538 - val_accuracy: 0.5459\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 3s 238ms/step - loss: 0.9541 - accuracy: 0.5456 - val_loss: 0.9537 - val_accuracy: 0.5459\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 2s 183ms/step - loss: 0.9541 - accuracy: 0.5456 - val_loss: 0.9540 - val_accuracy: 0.5459\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 2s 145ms/step - loss: 0.9544 - accuracy: 0.5456 - val_loss: 0.9538 - val_accuracy: 0.5459\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 2s 171ms/step - loss: 0.9539 - accuracy: 0.5456 - val_loss: 0.9537 - val_accuracy: 0.5459\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 3s 240ms/step - loss: 0.9539 - accuracy: 0.5456 - val_loss: 0.9544 - val_accuracy: 0.5459\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 3s 237ms/step - loss: 0.9546 - accuracy: 0.5456 - val_loss: 0.9539 - val_accuracy: 0.5459\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 3s 186ms/step - loss: 0.9548 - accuracy: 0.5456 - val_loss: 0.9552 - val_accuracy: 0.5459\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 2s 173ms/step - loss: 0.9542 - accuracy: 0.5456 - val_loss: 0.9541 - val_accuracy: 0.5459\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 2s 155ms/step - loss: 0.9539 - accuracy: 0.5456 - val_loss: 0.9539 - val_accuracy: 0.5459\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 2s 162ms/step - loss: 0.9544 - accuracy: 0.5456 - val_loss: 0.9544 - val_accuracy: 0.5459\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 3s 186ms/step - loss: 0.9557 - accuracy: 0.5456 - val_loss: 0.9539 - val_accuracy: 0.5459\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 2s 155ms/step - loss: 0.9540 - accuracy: 0.5456 - val_loss: 0.9539 - val_accuracy: 0.5459\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 2s 137ms/step - loss: 0.9543 - accuracy: 0.5456 - val_loss: 0.9537 - val_accuracy: 0.5459\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 2s 167ms/step - loss: 0.9546 - accuracy: 0.5456 - val_loss: 0.9539 - val_accuracy: 0.5459\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 2s 161ms/step - loss: 0.9539 - accuracy: 0.5456 - val_loss: 0.9541 - val_accuracy: 0.5459\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 3s 261ms/step - loss: 0.9540 - accuracy: 0.5456 - val_loss: 0.9539 - val_accuracy: 0.5459\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 3s 191ms/step - loss: 0.9544 - accuracy: 0.5456 - val_loss: 0.9538 - val_accuracy: 0.5459\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 2s 172ms/step - loss: 0.9540 - accuracy: 0.5456 - val_loss: 0.9543 - val_accuracy: 0.5459\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 2s 170ms/step - loss: 0.9544 - accuracy: 0.5456 - val_loss: 0.9541 - val_accuracy: 0.5459\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 2s 185ms/step - loss: 0.9537 - accuracy: 0.5456 - val_loss: 0.9568 - val_accuracy: 0.5459\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 3s 226ms/step - loss: 0.9549 - accuracy: 0.5456 - val_loss: 0.9543 - val_accuracy: 0.5459\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 3s 204ms/step - loss: 0.9550 - accuracy: 0.5456 - val_loss: 0.9545 - val_accuracy: 0.5459\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 2s 158ms/step - loss: 0.9538 - accuracy: 0.5456 - val_loss: 0.9539 - val_accuracy: 0.5459\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 2s 128ms/step - loss: 0.9539 - accuracy: 0.5456 - val_loss: 0.9538 - val_accuracy: 0.5459\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 2s 160ms/step - loss: 0.9539 - accuracy: 0.5456 - val_loss: 0.9539 - val_accuracy: 0.5459\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 2s 150ms/step - loss: 0.9547 - accuracy: 0.5456 - val_loss: 0.9540 - val_accuracy: 0.5459\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 2s 160ms/step - loss: 0.9541 - accuracy: 0.5456 - val_loss: 0.9537 - val_accuracy: 0.5459\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 3s 216ms/step - loss: 0.9541 - accuracy: 0.5456 - val_loss: 0.9537 - val_accuracy: 0.5459\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 2s 144ms/step - loss: 0.9538 - accuracy: 0.5456 - val_loss: 0.9536 - val_accuracy: 0.5459\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 2s 166ms/step - loss: 0.9537 - accuracy: 0.5456 - val_loss: 0.9538 - val_accuracy: 0.5459\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 2s 144ms/step - loss: 0.9546 - accuracy: 0.5456 - val_loss: 0.9538 - val_accuracy: 0.5459\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 2s 163ms/step - loss: 0.9539 - accuracy: 0.5456 - val_loss: 0.9536 - val_accuracy: 0.5459\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 4s 264ms/step - loss: 0.9540 - accuracy: 0.5456 - val_loss: 0.9538 - val_accuracy: 0.5459\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 2s 137ms/step - loss: 0.9540 - accuracy: 0.5456 - val_loss: 0.9541 - val_accuracy: 0.5459\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 2s 139ms/step - loss: 0.9541 - accuracy: 0.5456 - val_loss: 0.9541 - val_accuracy: 0.5459\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 2s 130ms/step - loss: 0.9540 - accuracy: 0.5456 - val_loss: 0.9537 - val_accuracy: 0.5459\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 2s 168ms/step - loss: 0.9545 - accuracy: 0.5456 - val_loss: 0.9540 - val_accuracy: 0.5459\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 2s 147ms/step - loss: 0.9537 - accuracy: 0.5456 - val_loss: 0.9539 - val_accuracy: 0.5459\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 2s 168ms/step - loss: 0.9543 - accuracy: 0.5456 - val_loss: 0.9540 - val_accuracy: 0.5459\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 2s 180ms/step - loss: 0.9544 - accuracy: 0.5456 - val_loss: 0.9538 - val_accuracy: 0.5459\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 2s 137ms/step - loss: 0.9537 - accuracy: 0.5456 - val_loss: 0.9537 - val_accuracy: 0.5459\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 2s 144ms/step - loss: 0.9539 - accuracy: 0.5456 - val_loss: 0.9537 - val_accuracy: 0.5459\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 2s 145ms/step - loss: 0.9539 - accuracy: 0.5456 - val_loss: 0.9537 - val_accuracy: 0.5459\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 2s 143ms/step - loss: 0.9540 - accuracy: 0.5456 - val_loss: 0.9537 - val_accuracy: 0.5459\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 2s 161ms/step - loss: 0.9537 - accuracy: 0.5456 - val_loss: 0.9537 - val_accuracy: 0.5459\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 3s 191ms/step - loss: 0.9539 - accuracy: 0.5456 - val_loss: 0.9537 - val_accuracy: 0.5459\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 2s 163ms/step - loss: 0.9539 - accuracy: 0.5456 - val_loss: 0.9537 - val_accuracy: 0.5459\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 2s 126ms/step - loss: 0.9538 - accuracy: 0.5456 - val_loss: 0.9537 - val_accuracy: 0.5459\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 2s 133ms/step - loss: 0.9538 - accuracy: 0.5456 - val_loss: 0.9538 - val_accuracy: 0.5459\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 2s 124ms/step - loss: 1.0171 - accuracy: 0.5402 - val_loss: 1.0045 - val_accuracy: 0.5459\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 2s 128ms/step - loss: 1.0190 - accuracy: 0.5456 - val_loss: 1.0292 - val_accuracy: 0.5459\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 2s 149ms/step - loss: 1.0228 - accuracy: 0.5456 - val_loss: 1.0141 - val_accuracy: 0.5459\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 3s 223ms/step - loss: 1.0097 - accuracy: 0.5461 - val_loss: 1.0051 - val_accuracy: 0.5454\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 2s 121ms/step - loss: 0.9984 - accuracy: 0.5461 - val_loss: 0.9959 - val_accuracy: 0.5459\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 2s 117ms/step - loss: 0.9920 - accuracy: 0.5456 - val_loss: 0.9876 - val_accuracy: 0.5459\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 2s 128ms/step - loss: 0.9852 - accuracy: 0.5456 - val_loss: 0.9820 - val_accuracy: 0.5459\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 2s 158ms/step - loss: 0.9805 - accuracy: 0.5456 - val_loss: 0.9784 - val_accuracy: 0.5459\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 2s 144ms/step - loss: 0.9777 - accuracy: 0.5456 - val_loss: 0.9770 - val_accuracy: 0.5459\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 2s 154ms/step - loss: 0.9759 - accuracy: 0.5456 - val_loss: 0.9734 - val_accuracy: 0.5459\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 2s 152ms/step - loss: 0.9724 - accuracy: 0.5456 - val_loss: 0.9708 - val_accuracy: 0.5459\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 2s 136ms/step - loss: 0.9699 - accuracy: 0.5456 - val_loss: 0.9692 - val_accuracy: 0.5459\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 2s 172ms/step - loss: 0.9694 - accuracy: 0.5456 - val_loss: 0.9678 - val_accuracy: 0.5459\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 2s 138ms/step - loss: 0.9671 - accuracy: 0.5456 - val_loss: 0.9662 - val_accuracy: 0.5459\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 2s 143ms/step - loss: 0.9660 - accuracy: 0.5456 - val_loss: 0.9650 - val_accuracy: 0.5459\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 2s 140ms/step - loss: 0.9645 - accuracy: 0.5456 - val_loss: 0.9638 - val_accuracy: 0.5459\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 3s 166ms/step - loss: 0.9635 - accuracy: 0.5456 - val_loss: 0.9629 - val_accuracy: 0.5459\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 2s 169ms/step - loss: 0.9629 - accuracy: 0.5456 - val_loss: 0.9621 - val_accuracy: 0.5459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "metadata": {
        "id": "PGaZtLCypo8H",
        "outputId": "2973afc2-d6a7-4c34-e7e1-a36839f21288",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best epoch: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_best_epoch = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "model_best_epoch.fit(padded_train_lyrics, y_train_2, epochs=best_epoch, batch_size=best_hps.get('batch_size'))"
      ],
      "metadata": {
        "id": "2Fd22W9vp2hu",
        "outputId": "78c23270-fbde-4ec4-c32c-0265ad8dcc5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 6s 191ms/step - loss: 2.6988 - accuracy: 0.5301\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e8994a7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_best_epoch = model_best_epoch.evaluate(padded_test_lyrics, y_test)\n",
        "accuracy_best_epoch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt3pdSMQkHQS",
        "outputId": "e4b5e13a-22fe-4518-a48f-1a415793b254"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 2s 10ms/step - loss: 2.2727 - accuracy: 0.5459\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.27274751663208, 0.5459098219871521]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Glove embedding__"
      ],
      "metadata": {
        "id": "KKLXrbkBwbdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_dictionary = dict()\n",
        "embedding_dim = 100\n",
        "\n",
        "# Load GloVe 100D embeddings\n",
        "with open('/content/drive/My Drive/Colab Notebooks/content/glove.6B.100d.txt', encoding='utf-8') as fp:\n",
        "    for line in fp.readlines():\n",
        "        records = line.split()\n",
        "        word = records[0]\n",
        "        vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
        "        embeddings_dictionary [word] = vector_dimensions\n",
        "\n",
        "# embeddings_dictionary"
      ],
      "metadata": {
        "id": "7r9Th4jOuopE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we will load embedding vectors of those words that appear in the\n",
        "# Glove dictionary. Others will be initialized to 0.\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_length, embedding_dim))\n",
        "\n",
        "for word, index in word_tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector\n",
        "        \n",
        "embedding_matrix"
      ],
      "metadata": {
        "id": "mHTo21PxupXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a85c9e6-987c-4598-f5d1-b52e67a06e38"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.2687    ,  0.81708002,  0.69896001, ..., -0.40110001,\n",
              "         0.74656999,  0.31121999],\n",
              "       [ 0.19073001,  0.56863999,  0.72026998, ..., -0.33460999,\n",
              "         0.044349  ,  0.57541001],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.41383001, -0.063647  ,  0.34494001, ..., -0.20672999,\n",
              "         0.22294   , -0.56507999],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_glove = Sequential()\n",
        "# embedding\n",
        "\n",
        "model_glove.add(\n",
        "    Embedding(input_dim=embedding_matrix.shape[0],\n",
        "              output_dim=embedding_matrix.shape[1],\n",
        "              weights = [embedding_matrix],\n",
        "              input_length=length_long_sentence))\n",
        "\n",
        "# first lstm\n",
        "model_glove.add(LSTM(128, return_sequences=True, kernel_initializer='glorot_uniform'))\n",
        "\n",
        "# drop out\n",
        "model_glove.add(Dropout(0.1))\n",
        "\n",
        "# second lstm\n",
        "model_glove.add(LSTM(128, kernel_initializer='glorot_uniform'))\n",
        "\n",
        "\n",
        "# dense layer\n",
        "model_glove.add(Dense(3,activation='softmax'))\n",
        "\n",
        "# compile\n",
        "model_glove.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "B9xLBkVcylz4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_glove.fit(padded_train_lyrics, y_train_2, epochs=100, batch_size = 512, validation_data = (padded_val_lyrics, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyAw_Mr30A7I",
        "outputId": "92e6e7bc-867d-45b5-9a9f-c76db7bb8f12"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 10s 317ms/step - loss: 0.9993 - accuracy: 0.5311 - val_loss: 0.9582 - val_accuracy: 0.5459\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 4s 253ms/step - loss: 0.9577 - accuracy: 0.5456 - val_loss: 0.9562 - val_accuracy: 0.5459\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 5s 349ms/step - loss: 0.9543 - accuracy: 0.5456 - val_loss: 0.9555 - val_accuracy: 0.5459\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 4s 259ms/step - loss: 0.9540 - accuracy: 0.5456 - val_loss: 0.9557 - val_accuracy: 0.5459\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 4s 253ms/step - loss: 0.9572 - accuracy: 0.5456 - val_loss: 0.9543 - val_accuracy: 0.5459\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 3s 212ms/step - loss: 0.9557 - accuracy: 0.5456 - val_loss: 0.9538 - val_accuracy: 0.5459\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 5s 322ms/step - loss: 0.9526 - accuracy: 0.5456 - val_loss: 0.9546 - val_accuracy: 0.5459\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 4s 245ms/step - loss: 0.9535 - accuracy: 0.5456 - val_loss: 0.9885 - val_accuracy: 0.5459\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 3s 228ms/step - loss: 0.9579 - accuracy: 0.5456 - val_loss: 0.9538 - val_accuracy: 0.5459\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 4s 270ms/step - loss: 0.9546 - accuracy: 0.5456 - val_loss: 0.9542 - val_accuracy: 0.5459\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 4s 263ms/step - loss: 0.9544 - accuracy: 0.5458 - val_loss: 0.9538 - val_accuracy: 0.5454\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 4s 273ms/step - loss: 0.9545 - accuracy: 0.5456 - val_loss: 0.9545 - val_accuracy: 0.5454\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 3s 223ms/step - loss: 0.9524 - accuracy: 0.5458 - val_loss: 0.9546 - val_accuracy: 0.5454\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.9484 - accuracy: 0.5459 - val_loss: 0.9528 - val_accuracy: 0.5459\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 3s 222ms/step - loss: 0.9484 - accuracy: 0.5458 - val_loss: 0.9603 - val_accuracy: 0.5454\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 4s 266ms/step - loss: 0.9476 - accuracy: 0.5458 - val_loss: 0.9579 - val_accuracy: 0.5454\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 3s 218ms/step - loss: 0.9412 - accuracy: 0.5458 - val_loss: 0.9697 - val_accuracy: 0.5459\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.9384 - accuracy: 0.5458 - val_loss: 0.9639 - val_accuracy: 0.5459\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 3s 227ms/step - loss: 0.9285 - accuracy: 0.5468 - val_loss: 0.9848 - val_accuracy: 0.5467\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 3s 189ms/step - loss: 0.9237 - accuracy: 0.5486 - val_loss: 0.9677 - val_accuracy: 0.5405\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 3s 217ms/step - loss: 0.9120 - accuracy: 0.5583 - val_loss: 0.9658 - val_accuracy: 0.5445\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 3s 224ms/step - loss: 0.9030 - accuracy: 0.5615 - val_loss: 0.9780 - val_accuracy: 0.5396\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 4s 288ms/step - loss: 0.9026 - accuracy: 0.5655 - val_loss: 1.0471 - val_accuracy: 0.5329\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 3s 229ms/step - loss: 0.8903 - accuracy: 0.5697 - val_loss: 1.0313 - val_accuracy: 0.5347\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 3s 204ms/step - loss: 0.8798 - accuracy: 0.5718 - val_loss: 1.0104 - val_accuracy: 0.5329\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 3s 193ms/step - loss: 0.8901 - accuracy: 0.5706 - val_loss: 1.0457 - val_accuracy: 0.4884\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 4s 273ms/step - loss: 0.8723 - accuracy: 0.5700 - val_loss: 1.0208 - val_accuracy: 0.5347\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 3s 193ms/step - loss: 0.8656 - accuracy: 0.5764 - val_loss: 1.0515 - val_accuracy: 0.5321\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 3s 215ms/step - loss: 0.8579 - accuracy: 0.5749 - val_loss: 1.0409 - val_accuracy: 0.5285\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 2s 181ms/step - loss: 0.8493 - accuracy: 0.5845 - val_loss: 1.0653 - val_accuracy: 0.5236\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 3s 228ms/step - loss: 0.8371 - accuracy: 0.5833 - val_loss: 1.0422 - val_accuracy: 0.5142\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 3s 216ms/step - loss: 0.8231 - accuracy: 0.5920 - val_loss: 1.2179 - val_accuracy: 0.4626\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 3s 230ms/step - loss: 0.7837 - accuracy: 0.6210 - val_loss: 1.1221 - val_accuracy: 0.5013\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 3s 188ms/step - loss: 0.7587 - accuracy: 0.6488 - val_loss: 1.2210 - val_accuracy: 0.4675\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 2s 170ms/step - loss: 0.7148 - accuracy: 0.6767 - val_loss: 1.3958 - val_accuracy: 0.4150\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 3s 256ms/step - loss: 0.7080 - accuracy: 0.6806 - val_loss: 1.3960 - val_accuracy: 0.4550\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 3s 166ms/step - loss: 0.6827 - accuracy: 0.7051 - val_loss: 1.4192 - val_accuracy: 0.4354\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 3s 179ms/step - loss: 0.6103 - accuracy: 0.7437 - val_loss: 1.2289 - val_accuracy: 0.4372\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 2s 181ms/step - loss: 0.7217 - accuracy: 0.6770 - val_loss: 1.0065 - val_accuracy: 0.5254\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 3s 215ms/step - loss: 0.7745 - accuracy: 0.6273 - val_loss: 1.1820 - val_accuracy: 0.4573\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 4s 258ms/step - loss: 0.6324 - accuracy: 0.7350 - val_loss: 1.2894 - val_accuracy: 0.4417\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 3s 193ms/step - loss: 0.6556 - accuracy: 0.7285 - val_loss: 1.2968 - val_accuracy: 0.4501\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 2s 181ms/step - loss: 0.5876 - accuracy: 0.7581 - val_loss: 1.4626 - val_accuracy: 0.4297\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 3s 217ms/step - loss: 0.6045 - accuracy: 0.7478 - val_loss: 1.3039 - val_accuracy: 0.4684\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 3s 207ms/step - loss: 0.5281 - accuracy: 0.7842 - val_loss: 1.4501 - val_accuracy: 0.4390\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 4s 268ms/step - loss: 0.4643 - accuracy: 0.8204 - val_loss: 1.6521 - val_accuracy: 0.4123\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 2s 158ms/step - loss: 0.4534 - accuracy: 0.8286 - val_loss: 1.5786 - val_accuracy: 0.4314\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 2s 172ms/step - loss: 0.4230 - accuracy: 0.8421 - val_loss: 1.7073 - val_accuracy: 0.4043\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 1s 109ms/step - loss: 0.3570 - accuracy: 0.8701 - val_loss: 1.9428 - val_accuracy: 0.4110\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 3s 182ms/step - loss: 0.3094 - accuracy: 0.8943 - val_loss: 1.9398 - val_accuracy: 0.4150\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 3s 243ms/step - loss: 0.3078 - accuracy: 0.8949 - val_loss: 1.9717 - val_accuracy: 0.4154\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 3s 211ms/step - loss: 0.3073 - accuracy: 0.8891 - val_loss: 1.8613 - val_accuracy: 0.4118\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 2s 161ms/step - loss: 0.2538 - accuracy: 0.9151 - val_loss: 1.9632 - val_accuracy: 0.4038\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 2s 157ms/step - loss: 0.2349 - accuracy: 0.9209 - val_loss: 2.0580 - val_accuracy: 0.4083\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 2s 155ms/step - loss: 0.2353 - accuracy: 0.9204 - val_loss: 2.1105 - val_accuracy: 0.4083\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 3s 193ms/step - loss: 0.2282 - accuracy: 0.9261 - val_loss: 2.1239 - val_accuracy: 0.4038\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 3s 217ms/step - loss: 0.2012 - accuracy: 0.9322 - val_loss: 2.2724 - val_accuracy: 0.4087\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 2s 170ms/step - loss: 0.1875 - accuracy: 0.9363 - val_loss: 2.1939 - val_accuracy: 0.4052\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 2s 185ms/step - loss: 0.1765 - accuracy: 0.9402 - val_loss: 2.2908 - val_accuracy: 0.4052\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 2s 156ms/step - loss: 0.1472 - accuracy: 0.9524 - val_loss: 2.3707 - val_accuracy: 0.3976\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 2s 170ms/step - loss: 0.1330 - accuracy: 0.9558 - val_loss: 2.4608 - val_accuracy: 0.3989\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 3s 239ms/step - loss: 0.1264 - accuracy: 0.9593 - val_loss: 2.5065 - val_accuracy: 0.3958\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 3s 198ms/step - loss: 0.1374 - accuracy: 0.9531 - val_loss: 2.4679 - val_accuracy: 0.3945\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 2s 157ms/step - loss: 0.6728 - accuracy: 0.7778 - val_loss: 1.4820 - val_accuracy: 0.4662\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 3s 195ms/step - loss: 0.5934 - accuracy: 0.7705 - val_loss: 1.3386 - val_accuracy: 0.4270\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 2s 158ms/step - loss: 0.4274 - accuracy: 0.8514 - val_loss: 1.5604 - val_accuracy: 0.4007\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 3s 187ms/step - loss: 0.3107 - accuracy: 0.8936 - val_loss: 1.8563 - val_accuracy: 0.4020\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 3s 245ms/step - loss: 0.2430 - accuracy: 0.9219 - val_loss: 2.0085 - val_accuracy: 0.4074\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 2s 169ms/step - loss: 0.2150 - accuracy: 0.9305 - val_loss: 2.1007 - val_accuracy: 0.3972\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 2s 167ms/step - loss: 0.1867 - accuracy: 0.9396 - val_loss: 2.1930 - val_accuracy: 0.3967\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 3s 179ms/step - loss: 0.1618 - accuracy: 0.9513 - val_loss: 2.3289 - val_accuracy: 0.4047\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 1s 108ms/step - loss: 0.1333 - accuracy: 0.9590 - val_loss: 2.3741 - val_accuracy: 0.3980\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 2s 171ms/step - loss: 0.1228 - accuracy: 0.9624 - val_loss: 2.4011 - val_accuracy: 0.3918\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 2s 163ms/step - loss: 0.1162 - accuracy: 0.9626 - val_loss: 2.4734 - val_accuracy: 0.3905\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 2s 108ms/step - loss: 0.1084 - accuracy: 0.9654 - val_loss: 2.5544 - val_accuracy: 0.3891\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 2s 144ms/step - loss: 0.1026 - accuracy: 0.9651 - val_loss: 2.5205 - val_accuracy: 0.3900\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 2s 168ms/step - loss: 0.0937 - accuracy: 0.9694 - val_loss: 2.5793 - val_accuracy: 0.3918\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 2s 159ms/step - loss: 0.1312 - accuracy: 0.9581 - val_loss: 2.5657 - val_accuracy: 0.3731\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 2s 171ms/step - loss: 0.1229 - accuracy: 0.9598 - val_loss: 2.4141 - val_accuracy: 0.3989\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 2s 162ms/step - loss: 0.1734 - accuracy: 0.9417 - val_loss: 2.4109 - val_accuracy: 0.3789\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 2s 145ms/step - loss: 0.1251 - accuracy: 0.9602 - val_loss: 2.5304 - val_accuracy: 0.3727\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 2s 134ms/step - loss: 0.1029 - accuracy: 0.9675 - val_loss: 2.5582 - val_accuracy: 0.3820\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 2s 144ms/step - loss: 0.1421 - accuracy: 0.9522 - val_loss: 2.4162 - val_accuracy: 0.3776\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 2s 117ms/step - loss: 0.1208 - accuracy: 0.9623 - val_loss: 2.4680 - val_accuracy: 0.3776\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 2s 144ms/step - loss: 0.1002 - accuracy: 0.9681 - val_loss: 2.5680 - val_accuracy: 0.3727\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 2s 173ms/step - loss: 0.0937 - accuracy: 0.9706 - val_loss: 2.6525 - val_accuracy: 0.3736\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 2s 129ms/step - loss: 0.0827 - accuracy: 0.9749 - val_loss: 2.7127 - val_accuracy: 0.3825\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 2s 144ms/step - loss: 0.0896 - accuracy: 0.9740 - val_loss: 2.7071 - val_accuracy: 0.3517\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 2s 143ms/step - loss: 0.0743 - accuracy: 0.9761 - val_loss: 2.7198 - val_accuracy: 0.3704\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 2s 120ms/step - loss: 0.0782 - accuracy: 0.9757 - val_loss: 2.7072 - val_accuracy: 0.3615\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 2s 143ms/step - loss: 0.0806 - accuracy: 0.9745 - val_loss: 2.7807 - val_accuracy: 0.3825\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 2s 156ms/step - loss: 0.0839 - accuracy: 0.9725 - val_loss: 2.7824 - val_accuracy: 0.3825\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 2s 160ms/step - loss: 0.0599 - accuracy: 0.9817 - val_loss: 2.8831 - val_accuracy: 0.3419\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 3s 228ms/step - loss: 0.0483 - accuracy: 0.9847 - val_loss: 3.0113 - val_accuracy: 0.3513\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 2s 129ms/step - loss: 0.0407 - accuracy: 0.9886 - val_loss: 3.0257 - val_accuracy: 0.3557\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 2s 119ms/step - loss: 0.0379 - accuracy: 0.9886 - val_loss: 3.0918 - val_accuracy: 0.3664\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 2s 166ms/step - loss: 0.0610 - accuracy: 0.9813 - val_loss: 3.0965 - val_accuracy: 0.3638\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 2s 131ms/step - loss: 0.0647 - accuracy: 0.9810 - val_loss: 3.1090 - val_accuracy: 0.3687\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 2s 145ms/step - loss: 0.0460 - accuracy: 0.9863 - val_loss: 3.1327 - val_accuracy: 0.3700\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 2s 130ms/step - loss: 0.0430 - accuracy: 0.9886 - val_loss: 3.1577 - val_accuracy: 0.3695\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe665db4ee0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_glove = model_glove.evaluate(padded_test_lyrics, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBUIOpwQ0G53",
        "outputId": "27bd6b8f-2872-4915-f929-bccc6ad87a74"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 1s 14ms/step - loss: 0.9723 - accuracy: 0.5379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_glove.fit(padded_train_lyrics, y_train_2, epochs=19, batch_size = 512, validation_data = (padded_val_lyrics, y_val))"
      ],
      "metadata": {
        "id": "9_qBBrUD2R4B",
        "outputId": "e6404f28-867f-4771-d3e7-3bb0e163e472",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/19\n",
            "14/14 [==============================] - 9s 321ms/step - loss: 1.0149 - accuracy: 0.5258 - val_loss: 0.9784 - val_accuracy: 0.5459\n",
            "Epoch 2/19\n",
            "14/14 [==============================] - 3s 217ms/step - loss: 0.9628 - accuracy: 0.5455 - val_loss: 0.9543 - val_accuracy: 0.5459\n",
            "Epoch 3/19\n",
            "14/14 [==============================] - 3s 205ms/step - loss: 0.9542 - accuracy: 0.5456 - val_loss: 0.9537 - val_accuracy: 0.5459\n",
            "Epoch 4/19\n",
            "14/14 [==============================] - 4s 255ms/step - loss: 0.9536 - accuracy: 0.5456 - val_loss: 0.9539 - val_accuracy: 0.5459\n",
            "Epoch 5/19\n",
            "14/14 [==============================] - 4s 242ms/step - loss: 0.9541 - accuracy: 0.5456 - val_loss: 0.9547 - val_accuracy: 0.5459\n",
            "Epoch 6/19\n",
            "14/14 [==============================] - 3s 198ms/step - loss: 0.9537 - accuracy: 0.5456 - val_loss: 0.9547 - val_accuracy: 0.5459\n",
            "Epoch 7/19\n",
            "14/14 [==============================] - 3s 196ms/step - loss: 0.9540 - accuracy: 0.5456 - val_loss: 0.9539 - val_accuracy: 0.5459\n",
            "Epoch 8/19\n",
            "14/14 [==============================] - 3s 184ms/step - loss: 0.9543 - accuracy: 0.5456 - val_loss: 0.9540 - val_accuracy: 0.5459\n",
            "Epoch 9/19\n",
            "14/14 [==============================] - 4s 288ms/step - loss: 0.9537 - accuracy: 0.5456 - val_loss: 0.9548 - val_accuracy: 0.5459\n",
            "Epoch 10/19\n",
            "14/14 [==============================] - 3s 192ms/step - loss: 0.9517 - accuracy: 0.5456 - val_loss: 0.9557 - val_accuracy: 0.5459\n",
            "Epoch 11/19\n",
            "14/14 [==============================] - 3s 201ms/step - loss: 0.9516 - accuracy: 0.5456 - val_loss: 0.9601 - val_accuracy: 0.5459\n",
            "Epoch 12/19\n",
            "14/14 [==============================] - 2s 180ms/step - loss: 0.9503 - accuracy: 0.5456 - val_loss: 0.9555 - val_accuracy: 0.5459\n",
            "Epoch 13/19\n",
            "14/14 [==============================] - 3s 192ms/step - loss: 0.9448 - accuracy: 0.5456 - val_loss: 0.9601 - val_accuracy: 0.5459\n",
            "Epoch 14/19\n",
            "14/14 [==============================] - 5s 288ms/step - loss: 0.9401 - accuracy: 0.5453 - val_loss: 0.9703 - val_accuracy: 0.5450\n",
            "Epoch 15/19\n",
            "14/14 [==============================] - 3s 195ms/step - loss: 0.9361 - accuracy: 0.5468 - val_loss: 0.9657 - val_accuracy: 0.5441\n",
            "Epoch 16/19\n",
            "14/14 [==============================] - 2s 168ms/step - loss: 0.9333 - accuracy: 0.5499 - val_loss: 0.9698 - val_accuracy: 0.5419\n",
            "Epoch 17/19\n",
            "14/14 [==============================] - 3s 189ms/step - loss: 0.9298 - accuracy: 0.5480 - val_loss: 0.9682 - val_accuracy: 0.5463\n",
            "Epoch 18/19\n",
            "14/14 [==============================] - 3s 186ms/step - loss: 0.9259 - accuracy: 0.5511 - val_loss: 0.9807 - val_accuracy: 0.5427\n",
            "Epoch 19/19\n",
            "14/14 [==============================] - 3s 215ms/step - loss: 0.9134 - accuracy: 0.5560 - val_loss: 0.9748 - val_accuracy: 0.5378\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe712c434c0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_RISRcTbNhjw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}